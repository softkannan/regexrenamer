#!/usr/bin/env python
# vim:fileencoding=utf-8
# License: GPLv3 Copyright: 2025, Kannan

import json

from calibre import prepare_string_for_xml
from calibre.web.feeds.recipes import BasicNewsRecipe

class ProjectMaduraiRecipe(BasicNewsRecipe):
    title = 'Project Madurai'
    __author__ = 'softk'
    description = 'Project Madurai is a digital library of Tamil literature.'
    language = 'ta'

    recipe_specific_options = {
        'url': {
            'short': 'Project Modurai html book link',
            'long': 'Project Modurai html book link',
            'default': ""
        }
    }

    def __init__(self, *args, **kwargs):
        BasicNewsRecipe.__init__(self, *args, **kwargs)
        d = self.recipe_specific_options.get('url')
        if d and isinstance(d, str):
            self.oldest_article = float(d)

        #
    #    **** IMPORTANT ****
    #
    #    DO NOT EDIT BELOW HERE UNLESS YOU KNOW WHAT YOU ARE DOING.
    #
    #    DO NOT EDIT BELOW HERE UNLESS YOU KNOW WHAT YOU ARE DOING.
    #
    #    I MEAN IT, YES I DO, ABSOLUTELY, AT YOU OWN RISK. :)
    #
    #    **** IMPORTANT ****
    #

    # Author of this recipe.
    __author__ = 'softk'

    # Specify English as the language of the RSS feeds (ISO-639 code).
    language = 'ta'

    # Set publisher and publication type.
    publication_type = 'book'
    encoding = 'utf-8'
    use_embedded_content = False

    # Removes empty feeds - why keep them!?
    remove_empty_feeds = True
    ignore_duplicate_articles = {'title', 'url'}
    resolve_internal_links = True

    def preprocess_raw_html(self, raw_html, url):
        start_index = raw_html.find('<article')
        end_index = raw_html.rfind('</article>') + len('</article>')
        if start_index != -1 and end_index != -1:
            return raw_html[start_index:end_index]
        return raw_html

    keep_only_tags = [
        dict(name='article')
    ]

    remove_tags = [
        dict(name=['button', 'svg', 'iframe']),
        dict(attrs={'data-component': ['ad-slot', 'tags', 'links-block', 'metadata-block', 'topic-list']})
    ]

    remove_attributes = ['style', 'height', 'width']
    no_stylesheets = True
    extra_css = '''
        figure,
        [data-component="byline-block"],
        [data-component="caption-block"],
        [data-component="image-block"] {
            font-size:small;
        }
    '''
    cover_url = 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/62/BBC_News_2019.svg/768px-BBC_News_2019.svg.png'
    masthead_url = 'https://upload.wikimedia.org/wikipedia/commons/4/41/BBC_Logo_2021.svg'

    def preprocess_html(self, soup):
        for placeholder in soup.findAll('img', attrs={'src': lambda x: x and x.endswith('placeholder.png')}):
            placeholder.decompose()
        for img in soup.findAll('img'):
            img.attrs = {'src': img.get('src', '')}
        for h2 in soup.findAll(['h2', 'h3']):
            h2.name = 'h4'
        return soup

